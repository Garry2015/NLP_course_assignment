{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础理论部分\n",
    "\n",
    "##### 0.Can you come up out 3 sceneraies which use AI methods?\n",
    "\n",
    "Ans: 1.语音识别。2.自动驾驶。3.人脸识别等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.What's the Probability Model?\n",
    "\n",
    "Ans:基于统计的模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.Can you came up with some sceneraies at which we could use Probability Model?\n",
    "\n",
    "Ans:机器翻译、语音识别。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.Why do we use probability and what's the difficult points for programming based on parsing and pattern match?\n",
    "\n",
    "Ans:1.基于文法规则的分析器没法处理复杂的语句。2.自然语言中词的多义性很难用规则来描述，二是严重依赖上下文，甚至是常识。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.What's the Language Model;\n",
    "\n",
    "Ans:所有合法（例如，通过一些语法约束）的字符串的集合称作一个语言，而一个语言模型就是这个语言里的字符串的概率分布模型。\n",
    "$$ language\\_model(String) = Probability(String) \\in (0, 1) $$\n",
    "$$ Pro(w_1 w_2 w_3 w_4 ...w_n) = P(w_1 | w_2 w_3 w_ 4...w_n) * P(w_2 | w_3 w_4...w_n) * P(w_3 | w_4...w_n) ... P(w_n)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.Can you came up with some sceneraies at which we could use Language Model?\n",
    "\n",
    "Ans:机器翻译、语音识别、手写体识别、拼写纠错、文献查询等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.What's the 1-gram language model;\n",
    "\n",
    "Ans:当 模型为如下时，称为1-gram langguage model。\n",
    "$$ Pro(w_1 w_2 w_3 w_4 ...w_n) = P(w_1) * P(w2) * P(w_3) ... P(w_n)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.What's the disadvantages and advantages of 1-gram language model;\n",
    "Ans:\n",
    "\n",
    "优点：空间复杂度和时间复杂度低\n",
    "\n",
    "缺点：准确率低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.What't the 2-gram models;\n",
    "Ans: $$ Pro(w_1 w_2 w_3 w_4...w_n) \\sim Pr(w_1 | w_2 ) * P(w_2 | w_3 ) * Pr(w_3 | w_4) * Pr(w_4|w_5)...(w_n)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法:\n",
    "\n",
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_1 =\"\"\"\n",
    "human = 人物 时间 地点_exp 动作\n",
    "人物 = 我 | 我们 | 大家\n",
    "时间 = 今天 | 明天 | 后天\n",
    "地点_exp = 去 地点\n",
    "地点 = 上海 | 北京 | 深圳\n",
    "动作 = 看海 | 旅游 | 比赛\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_2  = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾\n",
    "报数 = 我是工号 数字 ,\n",
    "数字 = 单个数字 | 数字 单个数字\n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士\n",
    "打招呼 = 你好 | 您好\n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 查询业务 | 办理业务\n",
    "查询业务 = 查询 具体业务\n",
    "办理业务 = 办理 具体业务\n",
    "具体业务 = 话费 | 积分 | 流量\n",
    "结尾 = 吗？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义语法生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str , split='='):\n",
    "    gram = {}\n",
    "    for line in grammar_str.split('\\n'):\n",
    "        if not line.strip(): continue\n",
    "        exp,smst = line.split(split)\n",
    "        gram[exp.strip()] = [s.split() for s in smst.split('|')]\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': [['人物', '时间', '地点_exp', '动作']],\n",
       " '人物': [['我'], ['我们'], ['大家']],\n",
       " '时间': [['今天'], ['明天'], ['后天']],\n",
       " '地点_exp': [['去', '地点']],\n",
       " '地点': [['上海'], ['北京'], ['深圳']],\n",
       " '动作': [['看海'], ['旅游'], ['比赛']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_1 = create_grammar(grammar_1)\n",
    "gram_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host': [['寒暄', '报数', '询问', '业务相关', '结尾']],\n",
       " '报数': [['我是工号', '数字', ',']],\n",
       " '数字': [['单个数字'], ['数字', '单个数字']],\n",
       " '单个数字': [['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9']],\n",
       " '寒暄': [['称谓', '打招呼'], ['打招呼']],\n",
       " '称谓': [['人称', ',']],\n",
       " '人称': [['先生'], ['女士']],\n",
       " '打招呼': [['你好'], ['您好']],\n",
       " '询问': [['请问你要'], ['您需要']],\n",
       " '业务相关': [['查询业务'], ['办理业务']],\n",
       " '查询业务': [['查询', '具体业务']],\n",
       " '办理业务': [['办理', '具体业务']],\n",
       " '具体业务': [['话费'], ['积分'], ['流量']],\n",
       " '结尾': [['吗？']]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_2 = create_grammar(grammar_2)\n",
    "gram_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义句子生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate(gram,target):\n",
    "    if target not in gram:\n",
    "        return target\n",
    "    exp = [generate(gram,t) for t in random.choice(gram[target])]    \n",
    "    return ''.join([s for s in exp if s != 'null'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用已此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我们后天去北京比赛'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1 = generate(gram_1,\"human\")\n",
    "sentence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'女士,你好我是工号5544,请问你要查询流量吗？'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_2 = generate(gram_2,\"host\")\n",
    "sentence_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(gram,target,n):\n",
    "    for i in range(n):\n",
    "        print(generate(gram,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我明天去上海比赛\n",
      "大家明天去深圳比赛\n",
      "我明天去上海旅游\n",
      "我们后天去上海看海\n",
      "我后天去北京比赛\n"
     ]
    }
   ],
   "source": [
    "generate_n(gram_1,\"human\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "女士,你好我是工号7,您需要查询流量吗？\n",
      "先生,您好我是工号93,您需要办理流量吗？\n",
      "您好我是工号482159423,您需要办理话费吗？\n",
      "女士,你好我是工号4,您需要办理流量吗？\n",
      "您好我是工号3,请问你要办理流量吗？\n"
     ]
    }
   ],
   "source": [
    "generate_n(gram_2,\"host\",5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 定义语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "##单个单词出现的概率\n",
    "def prob_1(word,tokens):\n",
    "    words_count = Counter(tokens)\n",
    "    prob = words_count[word] / len(tokens)\n",
    "    return prob if prob > 0 else (1 / len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "##两个单词的联合概率\n",
    "def prob_2(word1,word2,tokens):\n",
    "    tokens_2_gram = [\"\".join(tokens[i:i+2]) for i in range(len(tokens[:-1]))]\n",
    "    words_count_2 = Counter(tokens_2_gram)\n",
    "    if word1+word2 in tokens_2_gram:\n",
    "        return words_count_2[word1+word2]/len(tokens_2_gram)\n",
    "    else :\n",
    "        return 1/len(tokens_2_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "##求一个句子出现的概率\n",
    "def get_probablity(sentence,tokens):\n",
    "    words = cut(sentence)\n",
    "    sentence_pro = 1    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i + 1]        \n",
    "        probability = prob_2(word, next_,tokens)/prob_1(word,tokens)        \n",
    "        sentence_pro *= probability    \n",
    "    print(\"The probablity of sentence:{} is {}\".format(sentence,sentence_pro))\n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "movie_comments = pd.read_csv(\"./movie_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_contents = movie_comments['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def token(string):\n",
    "    return re.findall('\\w+',string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_contents_clean = [\"\".join(token(str(a))) for a in movie_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫到了脑残的地步看了恶心想吐',\n",
       " '首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视物理逻辑于不顾不得不说有钱真好随意胡闹',\n",
       " '吴京的炒作水平不输冯小刚但小刚至少不会用主旋律来炒作吴京让人看了不舒服为了主旋律而主旋律为了煽情而煽情让人觉得他是个大做作大谎言家729更新片子整体不如湄公河行动1整体不够流畅编剧有毒台词尴尬2刻意做作的主旋律煽情显得如此不合时宜而又多余',\n",
       " '凭良心说好看到不像战狼1的续集完虐湄公河行动',\n",
       " '中二得很',\n",
       " '犯我中华者虽远必诛吴京比这句话还要意淫一百倍',\n",
       " '脑子是个好东西希望编剧们都能有',\n",
       " '三星半实打实的7分第一集在爱国主旋律内部做着各种置换与较劲但第二集才真正显露吴京的野心他终于抛弃李忠志了新增外来班底让硬件实力有机会和国际接轨开篇水下长镜头和诸如铁丝网拦截RPG弹头的细节设计都让国产动作片重新封顶在理念上它甚至做到绣春刀2最想做到的那部分',\n",
       " '开篇长镜头惊险大气引人入胜结合了水平不俗的快剪下实打实的真刀真枪让人不禁热血沸腾特别弹簧床架挡炸弹空手接碎玻璃弹匣割喉等帅得飞起就算前半段铺垫节奏散漫主角光环开太大等也不怕作为一个中国人两个小时弥漫着中国强大得不可侵犯的氛围还是让那颗民族自豪心砰砰砰跳个不停',\n",
       " '15100吴京的冷峰在这部里即像成龙又像杰森斯坦森但体制外的同类型电影主角总是代表个人无能的政府需要求助于这些英雄才能解决难题体现的是个人的价值所以主旋律照抄这种模式实际上是有问题的我们以前嘲笑个人英雄主义却没想到捆绑爱国主义的全能战士更加难以下咽']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_contents_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_contents_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(data):\n",
    "    tokens=[]\n",
    "    for i in data:\n",
    "        tokens += cut(i)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE_TOKENS = cut_data(movie_contents_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_words_count = Counter(MOVIE_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328262),\n",
       " ('了', 102420),\n",
       " ('是', 73106),\n",
       " ('我', 50338),\n",
       " ('都', 36255),\n",
       " ('很', 34712),\n",
       " ('看', 34022),\n",
       " ('电影', 33675),\n",
       " ('也', 32065),\n",
       " ('和', 31290),\n",
       " ('在', 31245),\n",
       " ('不', 28435),\n",
       " ('有', 27939),\n",
       " ('就', 25685),\n",
       " ('人', 23909),\n",
       " ('好', 22858),\n",
       " ('啊', 20803),\n",
       " ('这', 17484),\n",
       " ('还', 17449),\n",
       " ('一个', 17343)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_words_count.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2270167418210582e-07"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2(\"我们\",\"电影\",MOVIE_TOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probablity of sentence:大家后天去北京比赛 is 3.443673457728388e-26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.443673457728388e-26"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probablity(generate(gram_1,\"human\"),MOVIE_TOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar,target,get_probablity,tokens_data,n=5):\n",
    "    probs = []\n",
    "    for i in range(n):\n",
    "        item = []\n",
    "        sentence = generate(grammar,target)\n",
    "        item.append(sentence)\n",
    "        prob = get_probablity(sentence,tokens_data)\n",
    "        item.append(prob)\n",
    "        probs.append(item)\n",
    "    probs = sorted(probs,key=lambda x: x[1], reverse=True)\n",
    "    return \"The best sentence is {} and the probablity is {}\".format(probs[0][0],probs[0][1])\n",
    "##[[句子1，概率1]，[句子2，概率2]，[句子2，概率2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probablity of sentence:大家后天去深圳旅游 is 1.5134787853362742e-10\n",
      "The probablity of sentence:我们明天去上海旅游 is 9.024839254422946e-12\n",
      "The probablity of sentence:大家今天去深圳比赛 is 5.3006630269841864e-11\n",
      "The probablity of sentence:我今天去上海比赛 is 2.527915957872056e-11\n",
      "The probablity of sentence:我们后天去上海比赛 is 2.0614632823260842e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The best sentence is 大家后天去深圳旅游 and the probablity is 1.5134787853362742e-10'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(gram_1,\"human\",get_probablity,MOVIE_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probablity of sentence:你好我是工号6,您需要办理积分吗？ is 4.518545329666473e-21\n",
      "The probablity of sentence:女士,您好我是工号1,请问你要办理话费吗？ is 3.375741284279462e-24\n",
      "The probablity of sentence:你好我是工号968,您需要办理话费吗？ is 5.930590745187247e-18\n",
      "The probablity of sentence:您好我是工号1,请问你要查询积分吗？ is 1.800394549713863e-23\n",
      "The probablity of sentence:先生,您好我是工号6,您需要查询话费吗？ is 4.61716643106069e-23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The best sentence is 你好我是工号968,您需要办理话费吗？ and the probablity is 5.930590745187247e-18'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(gram_2,\"host\",get_probablity,MOVIE_TOKENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ans:问题：当词只出现一次，或出现0次时，计算概率时会不正确。\n",
    "##### 提升：1.加大数据量。2.古德-图灵估计"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
